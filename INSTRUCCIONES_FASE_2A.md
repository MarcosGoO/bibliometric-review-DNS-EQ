# üìã INSTRUCCIONES - FASE 2A: AN√ÅLISIS TEM√ÅTICO (NLP)

## ‚úÖ SCRIPT GENERADO

He creado el script completo: `scripts/02A_analisis_tematico_NLP.R`

Este script implementa todas las funcionalidades necesarias para la Fase 2A seg√∫n las especificaciones t√©cnicas.

---

## üéØ ¬øQU√â HACE ESTE SCRIPT?

### 1. **Preprocesamiento de Texto**
- Carga los 335 documentos de `outputs/datos_fusionados.csv`
- Limpia abstracts (min√∫sculas, sin puntuaci√≥n, sin stopwords)
- Aplica stemming para normalizar t√©rminos
- Crea Document-Term Matrix (DTM) filtrada
- Guarda: `data/processed/corpus_cleaned.rds` y `dtm_filtered.rds`

### 2. **Extracci√≥n de Keywords con TF-IDF**
- Calcula scores TF-IDF para cada t√©rmino
- Extrae top 10 keywords por documento
- Combina con keywords originales (cuando existen)
- **SOLUCIONA** el problema de 60% sin keywords ‚Üí **100% cobertura**
- Guarda: tablas con rankings y estad√≠sticas

### 3. **Topic Modeling con LDA**
- **Optimiza** n√∫mero de topics (k) entre 5-12 usando m√©tricas:
  - CaoJuan2009 (minimizar)
  - Arun2010 (minimizar)
  - Deveaud2014 (maximizar)
- Entrena modelo LDA con par√°metros optimizados
- Asigna topic dominante a cada documento
- Propone etiquetas interpretables para cada topic
- Guarda: `data/processed/lda_model.rds`

### 4. **Genera 6 Visualizaciones Innovadoras**
1. **Topics Heatmap Temporal** - Evoluci√≥n de topics por a√±o (2016-2026)
2. **Alluvial Diagram** - Flujo de topics: Pre-COVID ‚Üí Durante ‚Üí Post-COVID
3. **Word Clouds por Topic** - Grid con cloud de cada topic
4. **Keywords Co-occurrence Network** - Red de co-apariciones con clusters
5. **Trend Topics Timeline** - L√≠neas temporales de proporci√≥n por topic
6. **LDA Optimization Metrics** - Gr√°fico de m√©tricas para selecci√≥n de k

### 5. **Tablas de Validaci√≥n**
- Estad√≠sticas de preprocesamiento
- Cobertura de keywords (original vs. extra√≠da)
- Top 50 keywords globales por TF-IDF
- Descripci√≥n detallada de cada topic
- Coherence scores (m√©trica de calidad)
- Distribuci√≥n de documentos por topic
- Topics por a√±o (tabla pivotada)

---

## üöÄ C√ìMO EJECUTAR

### Opci√≥n A: Desde RStudio (Recomendado)

1. **Abre RStudio**
2. **Abre el proyecto**: `article_didacsci.Rproj`
3. **Abre el script**: `scripts/02A_analisis_tematico_NLP.R`
4. **Ejecuta todo el script**:
   - Click en "Source" (ejecuta todo)
   - O selecciona todo (Ctrl+A) y Ctrl+Enter

### Opci√≥n B: Desde consola R

```r
setwd("c:/Users/marco/Documents/PROYECTOS/PORTFOLIO/article-didaccnat/article_didacsci")
source("scripts/02A_analisis_tematico_NLP.R")
```

---

## ‚è±Ô∏è TIEMPO DE EJECUCI√ìN

**Estimado: 10-20 minutos** (depende de tu CPU)

- Preprocesamiento: ~2 min
- TF-IDF: ~1 min
- **Optimizaci√≥n de k (LDA): ~5-10 min** ‚Üê parte m√°s lenta
- Entrenamiento LDA final: ~3 min
- Visualizaciones: ~2 min

### ‚ö° Acelerar si es necesario

Si quieres hacer una prueba r√°pida, en el script busca esta l√≠nea (aprox l√≠nea 270):

```r
result_k <- FindTopicsNumber(
```

Y **comenta todo ese bloque** hasta `optimal_k <- result_k$topics[...]`

Luego **descomenta** esta l√≠nea:
```r
# optimal_k <- 8
```

Esto usar√° directamente k=8 sin optimizar (ahorra ~10 minutos).

---

## üì¶ PAQUETES NECESARIOS

El script instalar√° autom√°ticamente todos los paquetes que falten:

**Core NLP:**
- `tm`, `SnowballC`, `quanteda`, `topicmodels`, `ldatuning`, `textclean`, `stringr`

**Visualizaci√≥n:**
- `tidyverse`, `wordcloud`, `ggwordcloud`, `ggalluvial`, `viridis`, `scales`, `patchwork`, `ggrepel`

**Redes:**
- `igraph`, `ggraph`, `tidygraph`

**Export:**
- `openxlsx`, `htmlwidgets`

Si hay alg√∫n error de instalaci√≥n, ejecuta manualmente:
```r
install.packages("nombre_del_paquete")
```

---

## üìÇ ARCHIVOS QUE SE GENERAR√ÅN

```
data/processed/
‚îú‚îÄ‚îÄ corpus_cleaned.rds
‚îú‚îÄ‚îÄ dtm_filtered.rds
‚îú‚îÄ‚îÄ lda_model.rds
‚îî‚îÄ‚îÄ datos_con_topics_y_keywords.csv  ‚Üê PRINCIPAL (dataset enriquecido)

outputs/figuras/tematicas/
‚îú‚îÄ‚îÄ 00_lda_optimization_metrics.png
‚îú‚îÄ‚îÄ 01_topics_heatmap_temporal.png
‚îú‚îÄ‚îÄ 02_topics_alluvial_evolution.png
‚îú‚îÄ‚îÄ 03_wordclouds_por_topic.png
‚îú‚îÄ‚îÄ 04_keywords_cooccurrence_network.png
‚îî‚îÄ‚îÄ 05_trend_topics_timeline.png

outputs/tablas/
‚îú‚îÄ‚îÄ 04_preprocesamiento_estadisticas.csv
‚îú‚îÄ‚îÄ 05_keywords_coverage.csv
‚îú‚îÄ‚îÄ 06_top_keywords_tfidf.csv
‚îú‚îÄ‚îÄ 07_topics_descripcion.csv
‚îú‚îÄ‚îÄ 08_topics_coherence_scores.csv
‚îú‚îÄ‚îÄ 09_topics_distribucion.csv
‚îî‚îÄ‚îÄ 10_topics_por_a√±o.csv
```

---

## ‚úÖ VERIFICAR RESULTADOS

Despu√©s de ejecutar, revisa:

### 1. **Visualizaciones**
- Abre `outputs/figuras/tematicas/`
- Verifica que las 6 im√°genes PNG se generaron
- Revisa que se vean correctamente (300 DPI)

### 2. **Tablas Clave**
- **`07_topics_descripcion.csv`**: ¬øLas etiquetas de topics tienen sentido?
- **`05_keywords_coverage.csv`**: ¬øAhora hay 100% cobertura?
- **`08_topics_coherence_scores.csv`**: ¬øCoherence >0.4 para todos los topics?

### 3. **Dataset Enriquecido**
- Abre `data/processed/datos_con_topics_y_keywords.csv`
- Verifica que tiene nuevas columnas:
  - `keywords_tfidf`
  - `keywords_combined`
  - `topic_id`
  - `topic_label`
  - `topic_probability`

---

## üîß AJUSTES MANUALES POSIBLES

### Si las etiquetas de topics no son apropiadas:

1. Ejecuta el script una vez
2. Revisa la tabla `07_topics_descripcion.csv`
3. Mira los **Top_10_Terms** de cada topic
4. Edita manualmente las etiquetas en el script (aprox l√≠nea 330):

```r
topic_labels <- c(
  "Technology-Enhanced Learning",      # Ajusta seg√∫n t√©rminos observados
  "Inquiry-Based Science Education",
  "Assessment & Evaluation",
  "Teacher Professional Development",
  "STEM Integration",
  "Equity & Social Justice",
  "Environmental Education",
  "Conceptual Understanding"
)[1:optimal_k]
```

5. Re-ejecuta solo desde la secci√≥n 5.4 en adelante

---

## ‚ö†Ô∏è POSIBLES ERRORES Y SOLUCIONES

### Error: "No se encuentra outputs/datos_fusionados.csv"
**Soluci√≥n**: Ejecuta primero `scripts/01_diagnostico_inicial_ACTUALIZADO.R`

### Error: Paquete X no se puede instalar
**Soluci√≥n**:
```r
install.packages("X", dependencies = TRUE, repos = "https://cloud.r-project.org")
```

### Error: "cannot allocate vector of size..."
**Soluci√≥n**: Tu PC tiene poca RAM. Reduce el corpus:
```r
df_trabajo <- df_trabajo %>% sample_n(200)  # Usa solo 200 docs para prueba
```

### Warning: "NAs introduced by coercion"
**Soluci√≥n**: Es normal en algunos pasos de limpieza, el script lo maneja autom√°ticamente.

---

## üìä INTERPRETACI√ìN DE RESULTADOS

### Coherence Score (m√©trica de calidad LDA)
- **< 0.4**: Topics poco coherentes, considera ajustar k
- **0.4 - 0.6**: Aceptable para an√°lisis exploratorio
- **> 0.6**: Excelente, topics bien definidos

### N√∫mero de Topics (k)
- **k muy bajo (5-6)**: Topics muy generales
- **k √≥ptimo (7-9)**: Balance entre granularidad e interpretabilidad
- **k muy alto (>10)**: Topics muy espec√≠ficos, dif√≠ciles de interpretar

### Distribuci√≥n de Documentos
- **Ideal**: Distribuci√≥n relativamente uniforme (cada topic 8-15%)
- **Problema**: Un topic domina >40% ‚Üí revisar preprocesamiento

---

## üéØ CRITERIOS DE √âXITO

Fase 2A ser√° exitosa si:

‚úÖ **Coverage de keywords: 100%** (vs 40% original)
‚úÖ **Coherence promedio: >0.4**
‚úÖ **Todos los topics tienen >5% documentos** (no hay topics "hu√©rfanos")
‚úÖ **Etiquetas de topics son interpretables** y reflejan la literatura
‚úÖ **Visualizaciones se generan sin errores** (300 DPI, legibles)
‚úÖ **Dataset enriquecido tiene >335 filas** con todas las columnas nuevas

---

## üìù NOTAS IMPORTANTES

1. **Seed fijada (12345)**: Garantiza reproducibilidad. Mismos resultados en cada ejecuci√≥n.

2. **A√±o 2026 parcial**: El script excluye 2026 de tendencias (solo 13 docs).

3. **Stopwords personalizadas**: Incluye t√©rminos muy gen√©ricos del dominio. Ajusta si es necesario.

4. **Stemming en ingl√©s**: Si tienes muchos docs en espa√±ol, considera ajustar:
   ```r
   tm_map(stemDocument, language = "spanish")
   ```

5. **TF-IDF vs Keywords originales**: El script **combina** ambos para maximizar cobertura.

---

## üöÄ DESPU√âS DE EJECUTAR

1. **Revisa visualizaciones** en `outputs/figuras/tematicas/`
2. **Valida topics** en tabla `07_topics_descripcion.csv`
3. **Ajusta etiquetas** si es necesario y re-ejecuta √∫ltima secci√≥n
4. **Guarda progreso** (commit en Git)
5. **Contin√∫a con Fase 2B**: An√°lisis de Redes

---

## üìß PREGUNTAS FRECUENTES

**P: ¬øPuedo cambiar el n√∫mero de keywords extra√≠das por documento?**
R: S√≠, busca `n_keywords <- 10` (l√≠nea ~172) y ajusta el valor.

**P: ¬øPuedo usar solo keywords originales sin TF-IDF?**
R: S√≠, pero tendr√°s 60% documentos sin keywords. No recomendado.

**P: ¬øCu√°ntos topics deber√≠a usar?**
R: Deja que el script optimice autom√°ticamente. T√≠picamente 7-9 es √≥ptimo.

**P: ¬øPuedo ejecutar esto en una laptop con 4GB RAM?**
R: S√≠, pero reduce el corpus para pruebas iniciales (ver secci√≥n de errores).

---

**Fecha de creaci√≥n**: Febrero 9, 2026
**Script**: `scripts/02A_analisis_tematico_NLP.R`
**Estado**: ‚úÖ Listo para ejecutar
