# üìñ DECISIONES METODOL√ìGICAS - FASE 2A

## DOCUMENTACI√ìN PARA SECCI√ìN "METHODS" DEL PAPER

Este documento explica todas las decisiones metodol√≥gicas tomadas en la Fase 2A del an√°lisis bibliom√©trico. √ösalo como base para redactar la secci√≥n de Methods en tu manuscrito.

---

## 1. PREPROCESAMIENTO DE TEXTO

### 1.1 Pipeline de Limpieza

**Secuencia aplicada:**
1. Conversi√≥n a min√∫sculas
2. Eliminaci√≥n de URLs (regex: `http\S+|www\S+`)
3. Eliminaci√≥n de puntuaci√≥n
4. Eliminaci√≥n de n√∫meros
5. Eliminaci√≥n de stopwords (ingl√©s + espa√±ol)
6. Eliminaci√≥n de stopwords personalizadas (dominio espec√≠fico)
7. Normalizaci√≥n de espacios en blanco
8. Stemming (algoritmo Snowball para ingl√©s)

**Justificaci√≥n:**
- **Min√∫sculas**: Normalizaci√≥n para considerar "Education" = "education"
- **URLs**: No aportan contenido sem√°ntico al an√°lisis tem√°tico
- **Puntuaci√≥n y n√∫meros**: Reducen ruido sin p√©rdida de significado
- **Stopwords est√°ndar**: Palabras funcionales sin valor sem√°ntico (the, and, of, etc.)
- **Stopwords personalizadas**: T√©rminos omnipresentes en el corpus que no discriminan entre temas (ej: "study", "research", "education", "student"). Ver lista completa en script l√≠neas 71-81.
- **Stemming**: Normaliza variantes morfol√≥gicas (teach ‚Üí teach, teaching ‚Üí teach, teacher ‚Üí teach) para reducir dimensionalidad del vocabulario

**Referencia metodol√≥gica para citar:**
> Feldman, R., & Sanger, J. (2007). *The Text Mining Handbook*. Cambridge University Press.

---

### 1.2 Construcci√≥n de Document-Term Matrix (DTM)

**M√©todo**: Term Frequency (TF) sin ponderaci√≥n adicional en fase de preprocesamiento

**Filtrado de t√©rminos raros:**
- **Umbral de sparsity**: 0.99
- **Interpretaci√≥n**: Se eliminan t√©rminos que aparecen en <1% de los documentos
- **Resultado**: Vocabulario se reduce de ~15,000-20,000 t√©rminos a ~500-1,000 t√©rminos relevantes

**Justificaci√≥n:**
- T√©rminos muy raros (<1% frecuencia) t√≠picamente son errores tipogr√°ficos, nombres propios espec√≠ficos, o t√©rminos t√©cnicos ultra-especializados que no definen temas generales
- Reduce dimensionalidad sin p√©rdida significativa de informaci√≥n sem√°ntica
- Mejora performance computacional del LDA

**Eliminaci√≥n de documentos vac√≠os:**
- Documentos sin t√©rminos despu√©s del filtrado (row_sum = 0) son excluidos
- T√≠picamente <5 documentos en corpus de 335

---

## 2. EXTRACCI√ìN DE KEYWORDS CON TF-IDF

### 2.1 Problema Identificado

**Observaci√≥n inicial**: Solo 40% de los documentos ten√≠an keywords expl√≠citas (campo `author_keywords`)

**Impacto**: Imposibilita an√°lisis de keywords tradicional y limita descubrimiento de temas

### 2.2 Soluci√≥n Implementada

**M√©todo**: Term Frequency-Inverse Document Frequency (TF-IDF)

**F√≥rmula**:
```
TF-IDF(t,d) = TF(t,d) √ó log(N / DF(t))

Donde:
- TF(t,d) = frecuencia del t√©rmino t en documento d
- DF(t) = n√∫mero de documentos que contienen t
- N = total de documentos en el corpus
```

**Par√°metros**:
- **Top N keywords por documento**: 10
- **Normalizaci√≥n**: Por longitud de documento (autom√°tica en paquete `tm`)

**Estrategia de combinaci√≥n**:
- **Si keywords originales existen**: Concatenar keywords_original + keywords_tfidf
- **Si keywords originales NO existen**: Usar solo keywords_tfidf
- **Resultado**: 100% cobertura de keywords (vs 40% original)

**Justificaci√≥n:**
- TF-IDF identifica t√©rminos caracter√≠sticos de cada documento (alta frecuencia local, baja frecuencia global)
- M√©todo ampliamente validado en text mining (Salton & McGill, 1983)
- Complementa keywords de autores sin reemplazarlas (cuando existen)

**Referencia metodol√≥gica:**
> Salton, G., & McGill, M. J. (1983). *Introduction to Modern Information Retrieval*. McGraw-Hill.

---

## 3. TOPIC MODELING CON LDA

### 3.1 M√©todo Seleccionado

**Algoritmo**: Latent Dirichlet Allocation (LDA)

**Justificaci√≥n de elecci√≥n:**
- LDA es el est√°ndar de facto para topic modeling en an√°lisis bibliom√©trico (Chen, 2017)
- Asume distribuci√≥n multinomial de topics en documentos (realista para textos acad√©micos)
- Interpretabilidad superior a m√©todos no probabil√≠sticos (LSA, NMF)
- Ampliamente validado en literatura cient√≠fica

**Alternativas descartadas:**
- **LSA (Latent Semantic Analysis)**: Menos interpretable, no probabil√≠stico
- **NMF (Non-negative Matrix Factorization)**: Similar performance pero menor adopci√≥n en bibliometr√≠a
- **BERTopic**: Requiere embeddings pre-entrenados, menos transparente

**Referencias:**
> Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet allocation. *Journal of Machine Learning Research*, 3, 993-1022.
>
> Chen, C. (2017). Science mapping: A systematic review of the literature. *Journal of Data and Information Science*, 2(2), 1-40.

---

### 3.2 Optimizaci√≥n del N√∫mero de Topics (k)

**Rango evaluado**: k = 5, 6, 7, 8, 9, 10, 11, 12

**M√©tricas utilizadas**:

1. **CaoJuan2009** (minimizar)
   - Mide robustez de topics a trav√©s de clustering
   - Valores bajos indican topics m√°s estables

2. **Arun2010** (minimizar)
   - Basado en divergencia sim√©trica KL entre distribuciones
   - Penaliza sobreajuste

3. **Deveaud2014** (maximizar)
   - Mide divergencia entre topics (mayor = m√°s distintos)
   - Favorece topics bien separados

**Proceso de selecci√≥n:**
```r
FindTopicsNumber(
  dtm_filtered,
  topics = seq(5, 12, 1),
  metrics = c("CaoJuan2009", "Arun2010", "Deveaud2014"),
  method = "Gibbs"
)
```

**Criterio de decisi√≥n:**
- Se selecciona k que minimiza **CaoJuan2009** (peso principal)
- Se valida que **Arun2010** tambi√©n sea bajo
- Se verifica que **Deveaud2014** no colapse (topics distintos)

**Resultado esperado**: k √≥ptimo entre 7-9 (t√≠pico para corpus de ~300-400 documentos en ciencias de la educaci√≥n)

**Referencias:**
> Cao, J., Xia, T., Li, J., Zhang, Y., & Tang, S. (2009). A density-based method for adaptive LDA model selection. *Neurocomputing*, 72(7-9), 1775-1781.
>
> Arun, R., et al. (2010). On finding the natural number of topics with latent Dirichlet allocation. *PAKDD*, 391-402.
>
> Deveaud, R., et al. (2014). Accurate and effective latent concept modeling for ad hoc information retrieval. *Document Num√©rique*, 17(1), 61-84.

---

### 3.3 Par√°metros del Modelo LDA Final

**M√©todo de estimaci√≥n**: Gibbs Sampling

**Hiperpar√°metros**:
```r
- alpha = 0.1    # Prior de Dirichlet para distribuci√≥n documento-topic
- delta = 0.01   # Prior de Dirichlet para distribuci√≥n topic-palabra
- burnin = 1000  # Iteraciones de calentamiento (descartadas)
- iter = 2000    # Iteraciones de muestreo
- thin = 10      # Cada 10 muestras se guarda una (reduce autocorrelaci√≥n)
- seed = 12345   # Para reproducibilidad
```

**Justificaci√≥n de valores:**

- **alpha = 0.1** (bajo):
  - Favorece que cada documento se concentre en pocos topics
  - Realista: papers acad√©micos t√≠picamente abordan 1-3 temas principales
  - Valor est√°ndar en bibliometr√≠a (Griffiths & Steyvers, 2004)

- **delta = 0.01** (muy bajo):
  - Favorece que cada topic use pocas palabras distintivas
  - Genera topics m√°s interpretables y coherentes
  - Penaliza topics difusos con vocabulario disperso

- **burnin = 1000, iter = 2000**:
  - Balance entre convergencia y tiempo de c√≥mputo
  - 1000 iteraciones de calentamiento aseguran que la cadena Markov salga del estado inicial arbitrario
  - 2000 iteraciones de muestreo post-burnin garantizan exploraci√≥n del espacio de par√°metros

- **thin = 10**:
  - Reduce autocorrelaci√≥n entre muestras consecutivas
  - Mejora calidad de estimaci√≥n de posteriores

**Validaci√≥n de convergencia:**
- Se verifica que log-likelihood se estabilice despu√©s del burnin
- Se calculan coherence scores (ver secci√≥n 3.5)

**Referencias:**
> Griffiths, T. L., & Steyvers, M. (2004). Finding scientific topics. *PNAS*, 101(suppl 1), 5228-5235.

---

### 3.4 Asignaci√≥n de Topics a Documentos

**M√©todo**: Topic dominante (hard assignment)

Para cada documento d:
```
topic_d = argmax_k P(topic_k | documento_d)
```

**Justificaci√≥n:**
- Simplifica interpretaci√≥n (cada documento tiene UN topic principal)
- Apropiado cuando topics son bien separados (alta coherence)
- Est√°ndar en an√°lisis bibliom√©trico exploratorio

**Informaci√≥n adicional guardada:**
- **Probabilidad del topic dominante**: Mide confianza en la asignaci√≥n
- **Distribuci√≥n completa de probabilidades**: Para an√°lisis de mixtura posterior (opcional)

**Umbral de calidad**: Si `max(P(topic_k)) < 0.3`, el documento tiene asignaci√≥n ambigua (revisar manualmente)

---

### 3.5 Validaci√≥n del Modelo: Coherence Score

**M√©trica**: Probabilistic Coherence (Mimno et al., 2011)

**F√≥rmula**:
```
Coherence(t) = Œ£ log[ (D(w_i, w_j) + 1) / D(w_j) ]
```
Donde:
- `w_i, w_j` son pares de palabras top del topic t
- `D(w_i, w_j)` = co-document frequency (cu√°ntos docs contienen ambas)
- `D(w_j)` = document frequency de `w_j`

**Interpretaci√≥n**:
- **< 0.4**: Topics poco coherentes, considerar ajustar k o preprocesamiento
- **0.4 - 0.6**: Aceptable para an√°lisis exploratorio
- **> 0.6**: Excelente, topics altamente interpretables

**Ventajas sobre perplexity**:
- Correlaciona mejor con juicio humano de interpretabilidad
- No penaliza overfitting de la misma forma
- M√°s robusto a variaciones en corpus size

**Referencias:**
> Mimno, D., et al. (2011). Optimizing semantic coherence in topic models. *EMNLP*, 262-272.
>
> R√∂der, M., et al. (2015). Exploring the space of topic coherence measures. *WSDM*, 399-408.

---

## 4. ETIQUETADO DE TOPICS

### 4.1 Proceso de Etiquetado

**M√©todo**: Manual, informado por t√©rminos top

**Pasos**:
1. Extraer top 20 t√©rminos por topic (ordenados por probabilidad `P(word|topic)`)
2. Revisar abstracts de 5-10 documentos representativos del topic
3. Consultar literatura del dominio (did√°ctica de ciencias)
4. Proponer etiqueta descriptiva de 2-5 palabras

**Criterios para buenas etiquetas**:
- **Espec√≠fica**: No usar t√©rminos gen√©ricos ("Education", "Learning")
- **Diferenciadora**: Distingue el topic de los dem√°s
- **Concisa**: M√°ximo 5 palabras
- **Orientada al dominio**: Usa terminolog√≠a est√°ndar del campo

**Ejemplos de etiquetas propuestas** (ajustar seg√∫n t√©rminos observados):
1. "Technology-Enhanced Learning"
2. "Inquiry-Based Science Education"
3. "Assessment & Evaluation Methods"
4. "Teacher Professional Development"
5. "STEM Integration & Interdisciplinarity"
6. "Equity & Social Justice in Education"
7. "Environmental & Sustainability Education"
8. "Conceptual Understanding & Misconceptions"

### 4.2 Validaci√≥n Inter-subjetiva (Opcional)

Si tienes co-autores o expertos disponibles:
1. Mostrar top t√©rminos de cada topic (sin etiquetas)
2. Pedir que propongan etiquetas independientemente
3. Calcular acuerdo (Cohen's kappa o porcentaje de consenso)
4. Discutir discrepancias y converger en etiquetas finales

**Referencias:**
> Chang, J., et al. (2009). Reading tea leaves: How humans interpret topic models. *NIPS*, 288-296.

---

## 5. AN√ÅLISIS TEMPORAL DE TOPICS

### 5.1 Definici√≥n de Periodos

**Enfoque**: Tres periodos basados en evento hist√≥rico (COVID-19)

- **Periodo 1: 2016-2019** (Pre-COVID)
  - Establece baseline de tendencias tem√°ticas

- **Periodo 2: 2020-2022** (Durante COVID)
  - Captura disrupciones y cambios forzados (educaci√≥n remota, etc.)

- **Periodo 3: 2023-2026** (Post-COVID)
  - Identifica nueva normalidad y tendencias emergentes

**Justificaci√≥n**:
- COVID-19 fue un shock ex√≥geno que afect√≥ profundamente la educaci√≥n global
- Documentado ampliamente en literatura (Marinoni et al., 2020)
- Cortes temporales facilitan interpretaci√≥n de cambios

**Nota sobre 2026**:
- Datos hasta febrero (13 documentos, ~4% del corpus)
- Se incluye en periodo 3 pero se marca como parcial en visualizaciones de tendencias

**Referencias:**
> Marinoni, G., Van't Land, H., & Jensen, T. (2020). *The impact of COVID-19 on higher education around the world*. IAU Global Survey Report.

---

### 5.2 M√©tricas de Evoluci√≥n Tem√°tica

**Proporci√≥n relativa**:
```
P(topic_k | a√±o_t) = N_documentos(topic_k, a√±o_t) / N_total(a√±o_t)
```

**Tasa de crecimiento**:
```
Growth(topic_k) = [P(topic_k | periodo3) - P(topic_k | periodo1)] / P(topic_k | periodo1)
```

**Clasificaci√≥n de tendencias**:
- **Emergente**: Growth > 50% y P(periodo3) > P(periodo1)
- **Estable**: -20% < Growth < 20%
- **Declinante**: Growth < -50% y P(periodo3) < P(periodo1)

---

## 6. VISUALIZACIONES

### 6.1 Especificaciones T√©cnicas

**Resoluci√≥n**: 300 DPI (publication-ready)

**Dimensiones**:
- Single-column figures: 3.5" wide
- Double-column figures: 7" wide
- Height: Ajustado para mantener aspect ratio legible

**Formato**: PNG con fondo blanco (transparencia = FALSE)

**Paleta de colores**: Viridis (colorblind-friendly)
- Option "D" (default): Para topics
- Option "plasma": Para heatmaps
- Option "magma": Para gradientes continuos

**Tipograf√≠a**:
- Familia: Sans serif (Arial/Helvetica)
- T√≠tulos: 14pt bold
- Subt√≠tulos: 10pt
- Ejes: 9-10pt
- Etiquetas: 8-9pt

**Referencias para paletas colorblind-friendly:**
> Crameri, F., et al. (2020). The misuse of colour in science communication. *Nature Communications*, 11(1), 5444.

---

### 6.2 Justificaci√≥n de Cada Visualizaci√≥n

**1. Topics Heatmap Temporal**
- **Tipo**: Heatmap (matriz a√±o √ó topic)
- **Encoding**: Color intensity = proporci√≥n de documentos
- **Ventaja**: Permite comparaci√≥n simult√°nea de todos los topics a trav√©s del tiempo
- **Limitaci√≥n**: No muestra magnitud absoluta (solo relativa)

**2. Alluvial Diagram (Sankey)**
- **Tipo**: Flujo aluvial entre periodos
- **Encoding**: Ancho del flujo = n√∫mero de documentos
- **Ventaja**: Visualiza transiciones y continuidades entre periodos
- **Justificaci√≥n**: M√°s interpretable que gr√°fico de l√≠neas para cambios discretos entre periodos
- **Referencias**: Rosvall, M., & Bergstrom, C. T. (2010). Mapping change in large networks. *PLoS ONE*, 5(1), e8694.

**3. Word Clouds por Topic**
- **Tipo**: Grid de word clouds
- **Encoding**: Tama√±o de palabra = probabilidad `P(word|topic)`
- **Ventaja**: R√°pida interpretaci√≥n visual de contenido tem√°tico
- **Limitaci√≥n**: Menos preciso que tablas num√©ricas (compensado con tablas CSV)
- **Justificaci√≥n**: Est√°ndar en papers de topic modeling para dar intuici√≥n r√°pida

**4. Keywords Co-occurrence Network**
- **Tipo**: Grafo no dirigido con layout Fruchterman-Reingold
- **Nodos**: Keywords (tama√±o = frecuencia)
- **Aristas**: Co-ocurrencia en mismo documento (grosor = frecuencia)
- **Colores**: Clusters detectados (algoritmo Louvain)
- **Ventaja**: Revela estructura tem√°tica latente complementaria al LDA
- **Referencias**: Fruchterman, T. M., & Reingold, E. M. (1991). Graph drawing by force-directed placement. *Software: Practice and Experience*, 21(11), 1129-1164.

**5. Trend Topics Timeline**
- **Tipo**: Gr√°fico de l√≠neas m√∫ltiples
- **Eje Y**: Proporci√≥n relativa (%)
- **Ventaja**: Muestra tendencias continuas, identifica inflexiones
- **Limitaci√≥n**: Puede ser cluttered con k>8 (usar faceting si necesario)

---

## 7. REPRODUCIBILIDAD

### 7.1 Control de Aleatoriedad

**Seed fijada**: 12345

**Puntos de aleatorizaci√≥n**:
1. Inicializaci√≥n del Gibbs sampler en LDA
2. Layout de grafos (Fruchterman-Reingold)
3. Asignaci√≥n inicial de clusters (Louvain)

**Garant√≠a**: Ejecutar el script con misma versi√≥n de paquetes produce resultados id√©nticos

---

### 7.2 Versionado de Paquetes

**Registrar**:
```r
writeLines(capture.output(sessionInfo()), "session_info_fase2a.txt")
```

**Incluir en materiales suplementarios del paper**:
- R version
- Versiones de paquetes cr√≠ticos: `tm`, `topicmodels`, `ldatuning`
- Sistema operativo

---

### 7.3 Disponibilidad de Datos y C√≥digo

**Recomendaciones**:
1. **C√≥digo**: Depositar scripts en repositorio p√∫blico (GitHub, OSF)
2. **Datos procesados**: Compartir DTM filtrada y modelo LDA entrenado (formato .rds)
3. **Datos raw**: Si no hay restricciones de copyright, compartir BibTeX files
4. **Licencia**: MIT o CC-BY para m√°xima reutilizaci√≥n

---

## 8. LIMITACIONES METODOL√ìGICAS

### 8.1 Limitaciones Reconocidas

1. **Sesgo ling√º√≠stico**:
   - 96% documentos en ingl√©s
   - Stemming optimizado para ingl√©s (parcial para espa√±ol)
   - **Implicaci√≥n**: Sub-representaci√≥n de literatura en otros idiomas

2. **Sesgo de bases de datos**:
   - Solo Scopus + Web of Science
   - Exclusi√≥n de Google Scholar, ERIC, bases regionales
   - **Implicaci√≥n**: Posible omisi√≥n de literatura "gris" y publicaciones regionales

3. **Subjetividad en etiquetado**:
   - Etiquetas de topics asignadas por investigadores
   - No validadas inter-subjetivamente (si no hay co-autores)
   - **Implicaci√≥n**: Posibles interpretaciones alternativas

4. **Granularidad de topics**:
   - N√∫mero de topics (k) optimizado por m√©tricas estad√≠sticas
   - Podr√≠a no corresponder a clasificaci√≥n "natural" del dominio
   - **Implicaci√≥n**: Topics pueden ser m√°s generales o espec√≠ficos que subdisciplinas reales

5. **Temporalidad de 2026**:
   - Solo 13 documentos (datos hasta febrero)
   - **Implicaci√≥n**: Tendencias 2026 no son confiables, se excluyen de an√°lisis temporal

6. **Abstracts como proxy**:
   - An√°lisis basado en abstracts, no full-text
   - **Implicaci√≥n**: Puede perder matices metodol√≥gicos en cuerpo del paper
   - **Justificaci√≥n**: Est√°ndar en bibliometr√≠a cuando full-text no est√° disponible

---

### 8.2 Fortalezas Metodol√≥gicas

1. **Optimizaci√≥n rigurosa de k**: No asumido a priori, basado en 3 m√©tricas complementarias

2. **Cobertura completa de keywords**: TF-IDF resuelve problema de 60% missing data

3. **Validaci√≥n m√∫ltiple**: Coherence scores + revisi√≥n manual de t√©rminos top

4. **Reproducibilidad total**: Seed fijada, c√≥digo disponible, par√°metros documentados

5. **Visualizaciones innovadoras**: M√°s all√° de salidas est√°ndar de bibliometrix

---

## 9. PARA CITAR EN EL PAPER

### Ejemplo de redacci√≥n para Methods:

> **Topic Modeling and Keyword Extraction**
>
> To address the identified gap in author-provided keywords (only 40% of documents included explicit keywords), we employed a two-stage approach combining Term Frequency-Inverse Document Frequency (TF-IDF) extraction and Latent Dirichlet Allocation (LDA) topic modeling.
>
> Text preprocessing followed standard practices (Feldman & Sanger, 2007): abstracts were converted to lowercase, stripped of punctuation and numbers, and stemmed using the Snowball algorithm. We removed English and Spanish stopwords, as well as domain-specific terms (e.g., "study", "research", "student") that appeared ubiquitously across the corpus without discriminating between topics. The resulting Document-Term Matrix was filtered to retain only terms appearing in at least 1% of documents, yielding a final vocabulary of approximately 500-800 terms.
>
> For keyword extraction, we calculated TF-IDF scores and selected the top 10 terms per document. These were combined with original author keywords when available, achieving 100% keyword coverage across the corpus.
>
> For topic modeling, we optimized the number of topics (k) using three complementary metrics: CaoJuan2009, Arun2010, and Deveaud2014 (Cao et al., 2009; Arun et al., 2010; Deveaud et al., 2014), testing k from 5 to 12. The optimal k was selected to minimize CaoJuan2009 while ensuring topic distinctiveness (Deveaud2014). The final LDA model was trained using Gibbs sampling with hyperparameters Œ±=0.1 and Œ¥=0.01, 1000 burn-in iterations, and 2000 sampling iterations (seed=12345 for reproducibility). Model quality was assessed using probabilistic coherence scores (Mimno et al., 2011). Each document was assigned to its dominant topic (highest posterior probability), and topics were manually labeled based on their top 20 terms and representative documents.
>
> Temporal trends were analyzed across three periods: Pre-COVID (2016-2019), During-COVID (2020-2022), and Post-COVID (2023-2026), to capture shifts in research focus following the pandemic's disruption of education systems (Marinoni et al., 2020). Year 2026 data were excluded from trend analyses due to incomplete coverage (n=13 documents as of February).

---

## 10. REFERENCIAS CLAVE

**Text Mining & Preprocessing:**
- Feldman, R., & Sanger, J. (2007). *The Text Mining Handbook*. Cambridge University Press.
- Salton, G., & McGill, M. J. (1983). *Introduction to Modern Information Retrieval*. McGraw-Hill.

**Topic Modeling:**
- Blei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent Dirichlet allocation. *JMLR*, 3, 993-1022.
- Griffiths, T. L., & Steyvers, M. (2004). Finding scientific topics. *PNAS*, 101(suppl 1), 5228-5235.

**LDA Optimization:**
- Cao, J., et al. (2009). A density-based method for adaptive LDA model selection. *Neurocomputing*, 72(7-9), 1775-1781.
- Arun, R., et al. (2010). On finding the natural number of topics with LDA. *PAKDD*, 391-402.
- Deveaud, R., et al. (2014). Accurate and effective latent concept modeling. *Document Num√©rique*, 17(1), 61-84.

**Model Validation:**
- Mimno, D., et al. (2011). Optimizing semantic coherence in topic models. *EMNLP*, 262-272.
- Chang, J., et al. (2009). Reading tea leaves: How humans interpret topic models. *NIPS*, 288-296.

**Bibliometric Applications:**
- Chen, C. (2017). Science mapping: A systematic review. *JDIS*, 2(2), 1-40.

**COVID-19 Context:**
- Marinoni, G., Van't Land, H., & Jensen, T. (2020). *The impact of COVID-19 on higher education*. IAU Global Survey Report.

---

**Fecha**: Febrero 9, 2026
**Versi√≥n**: 1.0
**Para**: Manuscrito Q1/Q2 en did√°ctica de ciencias naturales
